{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILD THE NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 신경망은 데이터에 대해 작업을 수행하는 층(layer)와 모듈로 구성되어있다 \n",
    "- torch.nn 은 Pytorch에서 신경망을 구성하는 다양한 레이어, 손실 함수, 활성화 함수 등과 같은 신경망과 관련된 모든 구성 요소를 포함하는 모듈이다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Device for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GPU가 사용되지 않는 이유\n",
    "    - CUDA와 GPU 드라이버 설치가 되어 있지 않는 경우\n",
    "    - Pytorch GPU 버전 설치 \n",
    "    - 환경 설정: GPU를 사용하기 위해 코드를 실행하는 환경이 GPU를 지원하도록 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- +cpu 로 표시되면 해당 PyTorch 버전은 CPU만 지원하는 버전"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 신경망을 정의하기 위해 PyTorch에서는 nn.Module을 서브클래싱(subclassing)하는 방식을 사용한다\n",
    "- 새로운 신경망 클래스를 정의할 때 nn.Module을 상속받기\n",
    "- __init__ 메서드에서 신경망의 레이어들을 초기화\n",
    "- forward 메서드 구현: forward 메서드는 입력 데이터에 대해 신경망의 연산을 수행하는 함수\n",
    "    - 신경망은 입력 데이터를 forward 메서드에 전달하면 이 메서드에서 정의된 레이어들과 연산들을 통해 출력을 계산한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    # nn.Modlue을 사용하기 위해 super().__init__()으로 초기화\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "        \n",
    "    # (forward pass) 연산을 정의\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([7])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PyTorch에서는 모델에 입력 데이터를 전달하면 내부적으로 forward 메서드가 자동으로 실행되기 때문에 forward 메서드를 직접 호출할 필요가 없다\n",
    "- 모델에 입력 데이터를 전달하면 모델은 순전파 연산을 수행하며, 예측 결과를 반환한다\n",
    "- 반환되는 결과는 2차원 텐서로, dim=0에는 각 클래스에 대한 10개의 로우(raw) 형태의 예측 값이 저장되고, dim=1에는 각 로우의 값들이 저장된다\n",
    "    -각 로우는 하나의 클래스에 해당하는 확률 값을 나타낸다\n",
    "- 이러한 로우(raw) 형태의 예측 값을 확률로 변환하기 위해 nn.Softmax 모듈을 사용한다\n",
    "\n",
    "\n",
    "- 모델 사용시 입력 데이터를 model(input_data)와 같이 전달하면 모델은 내부적으로 forward 메서드를 실행하여 예측 결과를 반환하고, 이후에 nn.Softmax 모듈을 사용하여 예측 결과를 확률로 변환한다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FashionMNIST 모델의 레이어를 분석해보기\n",
    "- 28x28인 3개의 이미지로 구성된 샘플 미니 배치를 가져와 네트워크를 통과할 때 어떤 일이 발생하는지 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 이미지 크기 확인\n",
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "# flatten으로 평탄화시킨다 28 x 28 -> 784\n",
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "# 3, 784의 평탄화된 데이터를 20차원으로 변환하여 선형 변환\n",
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[-0.0636, -0.0840,  0.0101,  0.5785,  0.0316, -0.1073,  0.3856, -0.0999,\n",
      "          0.3576, -0.2465,  0.1464,  0.1077, -0.3512, -1.0581, -0.1082, -0.4951,\n",
      "          0.2376, -0.0700, -0.0657,  0.1504],\n",
      "        [-0.3172, -0.1456, -0.1109,  0.2341,  0.0971, -0.2446,  0.1108, -0.2669,\n",
      "          0.2761, -0.1400,  0.0558,  0.1129, -0.4581, -0.9234, -0.2393, -0.4561,\n",
      "         -0.2453, -0.1588, -0.3922,  0.5081],\n",
      "        [-0.2455, -0.3443, -0.3474,  0.2802, -0.1236,  0.2399,  0.2598, -0.2068,\n",
      "          0.1800, -0.5162,  0.3509,  0.0742, -0.3100, -0.9622, -0.0195, -0.4625,\n",
      "          0.0494, -0.2617, -0.3763,  0.3353]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0000, 0.0000, 0.0101, 0.5785, 0.0316, 0.0000, 0.3856, 0.0000, 0.3576,\n",
      "         0.0000, 0.1464, 0.1077, 0.0000, 0.0000, 0.0000, 0.0000, 0.2376, 0.0000,\n",
      "         0.0000, 0.1504],\n",
      "        [0.0000, 0.0000, 0.0000, 0.2341, 0.0971, 0.0000, 0.1108, 0.0000, 0.2761,\n",
      "         0.0000, 0.0558, 0.1129, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.5081],\n",
      "        [0.0000, 0.0000, 0.0000, 0.2802, 0.0000, 0.2399, 0.2598, 0.0000, 0.1800,\n",
      "         0.0000, 0.3509, 0.0742, 0.0000, 0.0000, 0.0000, 0.0000, 0.0494, 0.0000,\n",
      "         0.0000, 0.3353]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ReLU를 적용하기 전에는 음수와 양수 모두 포함되어있지만\n",
    "- ReLU를 적용 이후에는 음수 값들이 0으로 변환되어 음수 값은 모두 제거되고, 양수 값들은 그대로 유지한다\n",
    "\n",
    "- ReLU\n",
    "    - ReLU 활성화 함수는 신경망의 비선형성을 증가시키는 역할\n",
    "    - 음수 값을 0으로 제거함으로써 데이터의 특징을 강조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nn.Sequential은 여러 개의 모듈을 순차적으로 쌓아서 하나의 모듈로 만드는 데 사용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0936, 0.1019, 0.1204, 0.0864, 0.0791, 0.0910, 0.0921, 0.1004, 0.1053,\n",
      "         0.1299],\n",
      "        [0.0886, 0.1019, 0.1292, 0.0844, 0.0779, 0.0872, 0.0872, 0.0960, 0.1152,\n",
      "         0.1323],\n",
      "        [0.0866, 0.1009, 0.1201, 0.0936, 0.0820, 0.0992, 0.0851, 0.1076, 0.0995,\n",
      "         0.1255]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([9, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n",
    "print(pred_probab)\n",
    "print(pred_probab.argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0042, -0.0200, -0.0299,  ...,  0.0142, -0.0069, -0.0057],\n",
      "        [ 0.0315, -0.0146,  0.0063,  ..., -0.0284, -0.0290,  0.0253]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([0.0202, 0.0021], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0441, -0.0004,  0.0019,  ...,  0.0097,  0.0181,  0.0381],\n",
      "        [ 0.0195,  0.0368,  0.0350,  ...,  0.0231,  0.0359,  0.0380]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([ 0.0360, -0.0263], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0149,  0.0112, -0.0419,  ..., -0.0129,  0.0051, -0.0111],\n",
      "        [ 0.0239,  0.0368, -0.0272,  ..., -0.0143, -0.0125,  0.0306]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([ 0.0299, -0.0022], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                 [-1, 2352]               0\n",
      "            Linear-2                   [-1, 20]          47,060\n",
      "              ReLU-3                   [-1, 20]               0\n",
      "            Linear-4                   [-1, 10]             210\n",
      "================================================================\n",
      "Total params: 47,270\n",
      "Trainable params: 47,270\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.18\n",
      "Estimated Total Size (MB): 0.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layer1 = nn.Linear(3*28*28, 20)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 모델 요약 정보 출력\n",
    "summary(model, input_size=(3, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                 [-1, 2352]               0\n",
      "            Linear-2                   [-1, 20]          47,060\n",
      "              ReLU-3                   [-1, 20]               0\n",
      "            Linear-4                   [-1, 10]             210\n",
      "================================================================\n",
      "Total params: 47,270\n",
      "Trainable params: 47,270\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.18\n",
      "Estimated Total Size (MB): 0.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3*28*28, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "summary(model, input_size=(3, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "linear_relu_stack.0.weight: torch.Size([512, 784])\n",
      "linear_relu_stack.0.bias: torch.Size([512])\n",
      "linear_relu_stack.2.weight: torch.Size([512, 512])\n",
      "linear_relu_stack.2.bias: torch.Size([512])\n",
      "linear_relu_stack.4.weight: torch.Size([10, 512])\n",
      "linear_relu_stack.4.bias: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# 매개변수 정보 출력\n",
    "print(\"Parameters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.size()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "torch.Size([512, 784])\n",
      "torch.Size([512])\n",
      "torch.Size([512, 512])\n",
      "torch.Size([512])\n",
      "torch.Size([10, 512])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# 매개변수 정보 출력\n",
    "print(\"Parameters:\")\n",
    "for param in model.parameters():\n",
    "    print(param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter Name: Parameter containing:\n",
      "tensor([[-0.0354, -0.0177, -0.0028,  ...,  0.0339,  0.0077, -0.0303],\n",
      "        [-0.0107,  0.0242,  0.0285,  ...,  0.0018,  0.0073,  0.0227],\n",
      "        [ 0.0018, -0.0128, -0.0081,  ...,  0.0153, -0.0113, -0.0037],\n",
      "        ...,\n",
      "        [-0.0221, -0.0334,  0.0128,  ..., -0.0166,  0.0340,  0.0204],\n",
      "        [ 0.0179,  0.0154, -0.0149,  ..., -0.0255, -0.0023, -0.0273],\n",
      "        [ 0.0312, -0.0137,  0.0276,  ..., -0.0272,  0.0164,  0.0130]],\n",
      "       requires_grad=True)\n",
      "Parameter Size: torch.Size([512, 784])\n",
      "Requires Gradient: True\n",
      "Gradient: None\n",
      "==============================\n",
      "Parameter Name: Parameter containing:\n",
      "tensor([ 1.2099e-02,  1.8562e-02,  4.0096e-03, -2.8859e-04, -3.5697e-02,\n",
      "         1.8410e-02, -3.4448e-02, -2.6702e-02, -6.1331e-03,  5.8703e-03,\n",
      "        -2.5006e-02, -1.2981e-02,  3.4689e-02,  3.1626e-02,  2.7608e-02,\n",
      "        -4.5151e-03, -1.5097e-02,  4.8268e-03,  9.9603e-03, -1.4238e-02,\n",
      "         8.6844e-03,  9.2927e-05,  9.6027e-03, -2.9572e-02, -1.0063e-02,\n",
      "         1.4774e-02,  3.3706e-02, -1.1424e-02,  2.2036e-02, -3.1405e-03,\n",
      "         6.2043e-03, -1.3054e-02,  1.3639e-02, -1.1663e-02,  7.3243e-03,\n",
      "        -4.1588e-03,  4.2853e-03,  1.6194e-02, -3.3735e-02, -1.1487e-02,\n",
      "         2.1180e-02,  2.5974e-02, -2.7840e-02, -2.0332e-02, -1.5053e-02,\n",
      "        -1.9679e-03, -3.0123e-02,  1.6464e-02,  3.2704e-03, -2.2574e-02,\n",
      "         2.6024e-02, -1.4726e-02,  1.0582e-02, -4.0116e-03, -1.8137e-02,\n",
      "         2.1568e-02, -7.2060e-03, -2.6869e-02, -1.4572e-02,  2.3623e-02,\n",
      "         2.1061e-02,  3.2635e-02,  2.4209e-02,  1.0854e-02, -2.5205e-02,\n",
      "         2.9538e-02,  1.8771e-02,  5.5047e-03, -2.3191e-02, -3.1318e-02,\n",
      "        -2.6916e-02, -1.2965e-02,  2.8875e-02, -2.5896e-02, -4.9060e-03,\n",
      "         1.5524e-02, -3.1959e-03, -8.1984e-03, -8.7579e-03,  8.0132e-03,\n",
      "        -2.8429e-03, -7.7433e-03, -8.5423e-03, -2.5223e-03,  3.3021e-02,\n",
      "        -3.3727e-02,  2.8273e-02,  1.6682e-02, -1.6300e-02, -1.7485e-02,\n",
      "         1.5768e-02, -2.6212e-02, -3.1888e-02, -1.5281e-02, -1.3748e-02,\n",
      "         7.3923e-03,  2.1175e-02,  4.8709e-03, -2.4772e-02,  2.9035e-02,\n",
      "        -1.4081e-02, -3.2745e-02, -7.3328e-03, -2.2857e-02,  2.7522e-03,\n",
      "         2.6017e-02,  2.0940e-02, -1.6073e-02,  1.2577e-02,  5.3879e-03,\n",
      "        -2.8389e-02, -3.2152e-03, -3.7440e-03,  4.4886e-03, -3.2735e-02,\n",
      "         2.4377e-02,  3.8698e-04, -2.3943e-02, -9.3581e-03,  2.5748e-02,\n",
      "        -2.3702e-02, -4.1253e-03,  9.1275e-03, -3.2968e-03,  7.1658e-03,\n",
      "        -6.2294e-03, -1.5359e-02,  2.3400e-02,  3.6804e-03, -1.1545e-02,\n",
      "         3.2148e-02,  1.1422e-02, -1.4996e-02, -4.9058e-03, -1.1001e-02,\n",
      "        -2.3522e-02,  3.0229e-02, -7.2107e-03, -3.3150e-02, -1.6504e-02,\n",
      "         1.8017e-02,  1.4411e-02, -1.2283e-02, -6.6466e-03,  2.7587e-02,\n",
      "        -2.0815e-02, -9.7964e-03,  2.5190e-02, -2.5664e-02, -1.3682e-02,\n",
      "         4.1694e-03,  2.2635e-02,  1.5412e-03,  2.5806e-02, -3.2951e-02,\n",
      "        -4.9379e-03, -2.9881e-02,  1.5962e-02, -2.8842e-02,  6.1474e-03,\n",
      "        -2.9720e-02,  2.3410e-02, -1.1909e-02,  1.0609e-02,  1.1670e-02,\n",
      "        -1.3423e-02,  1.7044e-02, -3.1930e-02,  5.3863e-03, -3.5669e-02,\n",
      "        -1.3564e-02,  1.1572e-02,  2.3213e-02, -3.2565e-02,  1.6226e-02,\n",
      "         1.4140e-02, -1.2265e-02, -7.6203e-04,  1.9262e-02,  1.1140e-02,\n",
      "         4.2434e-03, -4.6306e-03, -5.0148e-04, -3.1228e-02, -1.1613e-02,\n",
      "        -2.7445e-02, -5.9065e-03,  3.4692e-02, -2.4619e-02,  3.2428e-02,\n",
      "         2.6596e-02,  3.5525e-02, -1.7361e-02, -6.0570e-03,  7.2942e-03,\n",
      "         2.7583e-02,  4.2268e-03, -5.5078e-04, -3.0214e-02,  2.1703e-02,\n",
      "         1.8053e-02,  1.8906e-02, -4.6396e-03,  2.7825e-02, -1.9560e-02,\n",
      "         1.1525e-02, -1.6632e-02, -2.9204e-02,  2.3870e-02,  1.3790e-02,\n",
      "         1.4989e-02, -1.3531e-03,  1.4883e-02,  1.7540e-02,  3.3674e-02,\n",
      "        -3.2482e-03,  9.8803e-04, -3.5418e-02, -6.9154e-03, -3.1218e-02,\n",
      "         2.3018e-02,  9.3840e-06, -1.8045e-02,  2.6663e-02,  2.0451e-02,\n",
      "         3.3976e-02, -2.6456e-02,  1.5405e-02,  7.3709e-03,  1.2434e-02,\n",
      "        -1.0045e-02,  1.6051e-03,  1.7386e-02, -3.4210e-02, -8.1666e-03,\n",
      "         1.0077e-02,  1.1595e-02,  2.7809e-02, -2.1743e-02,  1.5520e-02,\n",
      "        -2.3442e-02,  2.5291e-02, -1.2534e-02, -2.9990e-02,  3.4096e-02,\n",
      "         2.9422e-02,  2.5575e-02, -2.2653e-03, -2.9892e-02,  1.7301e-02,\n",
      "        -1.5460e-02, -3.3575e-02, -1.0884e-03,  6.0517e-03,  2.8181e-02,\n",
      "         2.4796e-02,  2.0988e-02,  1.1612e-02, -2.6862e-03,  3.1897e-02,\n",
      "         3.4092e-02, -2.6378e-02,  3.2192e-02, -2.9599e-02, -2.6769e-02,\n",
      "        -1.8148e-03,  2.8236e-02,  2.8875e-02, -3.3839e-02, -1.2120e-02,\n",
      "         1.8412e-02,  3.2378e-02, -3.3010e-02,  1.2638e-03,  4.1994e-03,\n",
      "         3.4647e-02,  1.4293e-02, -1.1171e-02,  5.9513e-03, -6.3192e-03,\n",
      "        -3.4120e-04, -2.2581e-02, -2.5880e-02,  2.0228e-02, -2.0522e-02,\n",
      "         1.5331e-02, -1.6191e-02,  3.0034e-02,  3.0892e-02,  2.1478e-02,\n",
      "         1.6469e-02,  2.5448e-03, -3.3172e-02, -3.2375e-02,  2.8419e-02,\n",
      "         9.3124e-03, -2.2361e-02, -3.2267e-02,  2.7804e-02,  1.6087e-02,\n",
      "        -2.7139e-03,  2.7181e-02,  1.8470e-02,  2.2565e-02,  3.5331e-02,\n",
      "         3.3417e-02,  2.9189e-03,  5.9838e-03,  1.5444e-02,  2.3264e-02,\n",
      "        -1.1178e-02, -2.1884e-02, -1.3306e-02,  9.0060e-03,  2.5931e-02,\n",
      "         1.0645e-02,  3.3081e-02, -2.2248e-02, -1.8664e-02,  1.7900e-02,\n",
      "         3.3364e-02,  2.7287e-02,  3.4132e-02, -3.2658e-02, -1.0014e-02,\n",
      "        -3.4350e-02,  7.9990e-03, -1.9640e-02, -1.1723e-02, -2.1981e-02,\n",
      "        -6.3995e-03,  3.2783e-02,  1.3438e-04, -2.8860e-02, -2.6043e-02,\n",
      "        -6.9246e-03,  5.2522e-03,  2.5009e-02, -3.3060e-02,  3.5665e-03,\n",
      "         2.9985e-02,  1.3965e-02, -2.4399e-02,  3.4741e-02, -2.0579e-02,\n",
      "         1.1205e-02, -7.8197e-03, -1.4335e-02,  2.1868e-03,  1.4400e-03,\n",
      "         3.5255e-02,  2.5996e-03, -5.0206e-03,  3.0469e-02,  2.2502e-03,\n",
      "        -2.0605e-02,  3.3255e-04, -5.3635e-03,  3.3077e-02,  9.1039e-03,\n",
      "         3.1856e-02, -3.4558e-02,  3.2800e-02,  2.6575e-02,  1.1970e-02,\n",
      "         3.3013e-02, -8.7560e-03, -3.2532e-02,  5.9804e-04, -1.3355e-02,\n",
      "        -1.0910e-02, -2.1769e-02,  1.1465e-02, -1.9431e-02, -1.1972e-02,\n",
      "         1.0558e-02,  2.0068e-02, -2.8315e-02, -6.1786e-03, -2.0335e-02,\n",
      "         2.9063e-02,  7.3743e-03,  9.4059e-03, -9.4086e-03, -1.6324e-02,\n",
      "        -1.6434e-02,  1.2210e-02,  3.1939e-02, -8.5060e-05, -2.6781e-03,\n",
      "        -9.2001e-03,  2.5161e-02,  2.8765e-02, -3.5423e-02, -6.6155e-04,\n",
      "         1.6633e-02, -3.4705e-02, -1.3112e-03, -1.3655e-03, -2.3349e-02,\n",
      "         2.0885e-02, -3.5549e-02,  2.3807e-02, -4.7122e-03, -9.5019e-03,\n",
      "        -1.5315e-02, -1.2606e-03,  8.6155e-03, -2.0633e-02,  1.9146e-02,\n",
      "        -2.4750e-02,  1.1326e-02, -1.8208e-02, -3.2328e-02, -3.5369e-02,\n",
      "         2.2595e-02, -1.9215e-02, -2.3508e-02,  2.6924e-02,  2.1353e-02,\n",
      "         2.5911e-02,  7.2844e-03,  2.9467e-02,  6.4457e-03,  6.9678e-03,\n",
      "        -2.7332e-02, -2.0748e-02, -4.8524e-03,  8.0628e-03,  3.4797e-02,\n",
      "         3.3075e-02, -1.4967e-02, -3.2092e-02,  1.0118e-02,  1.7257e-02,\n",
      "        -1.2406e-02, -9.2567e-03, -1.7205e-02,  2.6310e-02,  3.5385e-02,\n",
      "         2.9443e-02, -2.6019e-03, -1.8916e-02, -1.9177e-02,  2.2824e-02,\n",
      "         4.3549e-03, -3.1286e-03, -2.3753e-03,  2.1003e-02, -1.4327e-02,\n",
      "         6.3118e-03,  3.7057e-03,  1.4062e-02, -3.3600e-02, -2.3549e-02,\n",
      "        -1.0089e-02,  1.7969e-03,  3.4782e-02,  6.3629e-03, -9.3452e-04,\n",
      "        -3.4665e-02, -8.4470e-03, -6.8390e-03, -6.5079e-03,  3.0505e-02,\n",
      "        -1.9486e-02,  4.8846e-03, -9.3371e-03, -1.7667e-03, -2.5466e-03,\n",
      "         2.1812e-02,  3.4341e-02, -1.0791e-02,  3.0768e-02, -3.0309e-02,\n",
      "        -1.8543e-02,  2.1208e-02, -2.5877e-03,  2.6696e-02,  2.9406e-03,\n",
      "         1.0904e-02, -1.3555e-03, -1.5739e-02, -3.2780e-02,  2.6016e-02,\n",
      "         5.4867e-03,  4.8190e-03,  4.3831e-03,  2.6761e-02,  2.1196e-02,\n",
      "         3.0452e-02,  2.2055e-02,  1.3775e-02, -3.2181e-03,  3.0036e-02,\n",
      "         2.2756e-02,  1.3989e-02, -3.2609e-03, -2.4811e-02,  2.9944e-02,\n",
      "         1.1436e-02, -1.9230e-02, -3.4530e-02, -3.2026e-02, -3.3674e-02,\n",
      "        -2.5315e-02,  2.6594e-02,  1.7426e-02,  5.3964e-03,  7.5578e-03,\n",
      "        -7.5654e-03,  2.5386e-02], requires_grad=True)\n",
      "Parameter Size: torch.Size([512])\n",
      "Requires Gradient: True\n",
      "Gradient: None\n",
      "==============================\n",
      "Parameter Name: Parameter containing:\n",
      "tensor([[-0.0008,  0.0379,  0.0312,  ..., -0.0351, -0.0085, -0.0265],\n",
      "        [-0.0188, -0.0247,  0.0085,  ...,  0.0285,  0.0035, -0.0395],\n",
      "        [-0.0201,  0.0374, -0.0022,  ..., -0.0177, -0.0363,  0.0345],\n",
      "        ...,\n",
      "        [ 0.0166, -0.0234,  0.0075,  ...,  0.0206,  0.0208,  0.0153],\n",
      "        [-0.0151, -0.0143, -0.0383,  ...,  0.0366, -0.0365,  0.0241],\n",
      "        [ 0.0094,  0.0007, -0.0413,  ...,  0.0225, -0.0013, -0.0267]],\n",
      "       requires_grad=True)\n",
      "Parameter Size: torch.Size([512, 512])\n",
      "Requires Gradient: True\n",
      "Gradient: None\n",
      "==============================\n",
      "Parameter Name: Parameter containing:\n",
      "tensor([-3.1514e-02, -3.8359e-02,  2.7256e-02,  3.2793e-02,  2.3025e-02,\n",
      "        -2.1212e-02,  6.1160e-03, -2.7886e-02, -2.0561e-02,  6.3123e-03,\n",
      "         2.5009e-02,  3.3425e-02, -1.6874e-02, -4.1061e-02, -3.8533e-02,\n",
      "        -2.1052e-03, -1.3301e-02, -1.7999e-03, -1.9834e-02,  3.9430e-02,\n",
      "         2.9137e-02,  1.4629e-02, -1.9501e-02,  5.1348e-03,  3.4172e-02,\n",
      "         2.0710e-02,  1.2191e-02,  1.4052e-02, -3.4686e-02, -2.6194e-02,\n",
      "        -2.8412e-02,  1.2636e-02, -3.8763e-02, -3.4500e-02,  3.9887e-02,\n",
      "         1.4877e-02,  3.0616e-02,  3.6002e-02, -1.9324e-02, -1.9961e-02,\n",
      "         3.1249e-02, -3.2194e-02, -7.8576e-03,  2.3259e-02,  3.2949e-02,\n",
      "         7.6230e-03,  2.7309e-02,  2.9985e-02, -6.1339e-04, -1.7645e-03,\n",
      "        -3.6222e-03,  3.1198e-02,  4.4870e-04,  1.9782e-02,  1.9113e-02,\n",
      "         2.0945e-02, -2.9995e-02, -3.9166e-02,  3.1838e-02,  3.8629e-02,\n",
      "        -1.8127e-02,  2.0795e-02,  4.1234e-02, -1.6564e-02, -4.1738e-02,\n",
      "         1.3721e-02,  1.4774e-02,  3.7353e-02, -5.0757e-03,  1.3231e-02,\n",
      "         1.1652e-02, -2.6079e-02,  8.8141e-03,  3.0413e-03,  7.8234e-03,\n",
      "        -8.0609e-03,  3.3558e-02,  1.7137e-02,  3.6668e-02, -3.9557e-02,\n",
      "         3.0816e-02, -1.7560e-02, -4.9037e-04,  3.2239e-02, -4.2231e-02,\n",
      "         2.1742e-02,  1.9683e-03,  4.2746e-02,  2.7838e-02,  2.0307e-02,\n",
      "         4.1744e-02,  4.0286e-02,  2.9816e-03,  4.0107e-04, -1.5633e-02,\n",
      "         2.9220e-02,  1.7446e-02,  1.9037e-03, -4.1726e-02,  2.8256e-03,\n",
      "         2.4063e-02,  3.5426e-02,  4.0935e-02,  3.8320e-02,  2.1595e-02,\n",
      "        -1.6957e-03,  3.1491e-02, -3.6358e-02,  1.9881e-02, -9.1834e-04,\n",
      "        -8.9981e-03, -1.6594e-02,  1.6612e-02, -4.2767e-02,  2.5711e-02,\n",
      "        -1.2795e-02, -3.9620e-02, -3.6814e-02, -1.6622e-02, -3.3087e-02,\n",
      "         3.0663e-02,  2.8460e-03,  8.5103e-03, -3.4604e-02, -3.9824e-02,\n",
      "         1.6942e-02, -4.2725e-02, -1.1680e-02, -3.0576e-02,  2.9425e-02,\n",
      "        -3.0115e-02, -2.9371e-02,  5.6216e-03,  2.7319e-02, -8.6219e-03,\n",
      "         2.5801e-02,  3.0024e-02, -1.0185e-02, -3.7764e-02, -2.5931e-02,\n",
      "         1.2405e-02, -2.0579e-02,  3.0793e-02, -1.9107e-02, -1.9706e-02,\n",
      "        -2.8892e-02, -4.1810e-02, -2.4388e-02, -2.5165e-02, -1.3785e-02,\n",
      "         4.2715e-02,  1.0410e-02,  1.2497e-02,  3.5564e-02,  2.5997e-03,\n",
      "         4.3300e-02, -5.1350e-03, -6.6210e-03, -6.6595e-03,  4.4589e-03,\n",
      "        -2.7112e-02, -2.1544e-02,  4.2035e-02, -1.6410e-02, -2.0286e-02,\n",
      "         7.5109e-03,  2.1037e-02,  2.1330e-03,  3.7642e-02, -3.9573e-02,\n",
      "        -1.8700e-02,  1.9975e-02,  2.6301e-02, -3.0197e-03, -4.2763e-02,\n",
      "        -3.8539e-02, -4.2322e-02, -2.2901e-02, -1.5332e-02,  1.9059e-02,\n",
      "         2.1609e-02, -2.9944e-02, -2.3618e-02,  1.8963e-02, -1.7671e-02,\n",
      "         3.2412e-02,  6.3587e-03, -4.8728e-03, -4.3559e-02,  9.2058e-03,\n",
      "        -1.0026e-02, -2.5180e-02,  1.4768e-02, -1.9440e-02,  1.8196e-02,\n",
      "        -1.3944e-02,  4.0144e-02,  4.0442e-03,  3.6640e-02,  1.5413e-02,\n",
      "        -2.1384e-02,  4.5404e-03,  6.6349e-03,  2.7134e-02,  2.9073e-03,\n",
      "         2.6770e-02,  4.1361e-02, -8.2681e-03,  1.6660e-02, -2.7773e-02,\n",
      "         1.2969e-02,  3.9622e-02,  1.9194e-02, -3.2800e-02, -2.6466e-02,\n",
      "        -9.8110e-04, -4.5849e-04,  3.5826e-02, -1.0884e-02, -3.8616e-02,\n",
      "         8.6820e-04, -2.7840e-02,  1.7864e-02,  3.7673e-02,  3.1768e-02,\n",
      "        -1.5813e-02, -1.8908e-02,  9.8238e-03,  1.8377e-02,  3.9559e-05,\n",
      "        -3.5099e-02, -4.6848e-03,  9.2287e-05,  3.6468e-02, -6.4897e-03,\n",
      "         2.4787e-02,  1.9223e-02, -3.8383e-03, -3.0143e-02,  3.2219e-02,\n",
      "        -1.9882e-02,  4.0958e-02,  3.5654e-02, -1.7011e-02, -1.4709e-02,\n",
      "        -3.5071e-02, -2.0110e-02, -1.7253e-02,  3.4981e-02, -3.7586e-02,\n",
      "         1.2201e-02,  2.9499e-02,  3.8942e-02, -2.4067e-03, -2.2544e-02,\n",
      "         4.2655e-02,  9.6613e-04, -4.4017e-02, -3.2289e-02, -3.0343e-02,\n",
      "        -1.5668e-02, -2.0813e-02,  3.0702e-02, -2.7931e-02, -2.1716e-02,\n",
      "         1.1748e-02, -4.0440e-02, -8.3924e-04,  1.0074e-02,  2.8092e-02,\n",
      "         2.8116e-02, -8.8311e-03, -3.3860e-02,  7.8206e-03,  4.2396e-04,\n",
      "         1.6181e-02, -9.3480e-03,  2.1137e-02,  3.5580e-02, -3.8326e-02,\n",
      "         7.8987e-03, -4.4750e-03, -9.8816e-04, -9.2549e-03, -1.5059e-02,\n",
      "        -2.7217e-02,  4.2522e-02,  2.8317e-02,  3.8997e-02,  1.4592e-02,\n",
      "         2.7569e-02,  1.4988e-02,  3.2223e-02,  1.9566e-02, -4.5786e-03,\n",
      "         1.7440e-02, -1.2221e-02, -3.2816e-02,  3.9898e-02,  3.6675e-02,\n",
      "         6.3382e-03, -2.6814e-02,  2.9726e-02, -3.4485e-02,  3.5026e-02,\n",
      "        -1.1195e-02,  2.9484e-02, -2.7565e-02,  1.4196e-02, -4.2636e-02,\n",
      "         2.8505e-02, -2.7401e-02,  4.2820e-02, -2.2684e-02,  2.6398e-02,\n",
      "        -3.0295e-02, -2.7684e-02,  3.1677e-03,  3.8454e-02,  5.7051e-03,\n",
      "        -6.4498e-03,  2.8321e-02, -2.9256e-02, -1.6266e-03, -4.0951e-02,\n",
      "         1.0745e-02,  2.8586e-02, -1.6046e-02,  3.8679e-02, -1.2049e-02,\n",
      "        -3.9540e-03,  7.9532e-03, -2.4654e-02, -1.9562e-02, -2.0407e-02,\n",
      "         1.0171e-02, -6.5097e-03, -4.1127e-02,  1.5002e-02,  1.1520e-02,\n",
      "         3.8353e-02, -2.3316e-02, -2.0910e-03, -7.9429e-03, -2.5424e-02,\n",
      "         6.4342e-03,  2.6379e-02,  1.1044e-02, -1.0726e-03, -3.9931e-02,\n",
      "        -4.6772e-03,  2.5173e-02, -5.8691e-03,  2.8242e-02,  3.1088e-03,\n",
      "         2.9011e-02, -8.2872e-03, -1.8493e-03,  1.1042e-02, -2.0130e-02,\n",
      "         2.4523e-02,  4.0318e-02, -2.3011e-02,  2.2436e-02,  2.9095e-03,\n",
      "        -1.5892e-03,  3.2362e-02, -4.0205e-02, -1.4130e-02, -6.8509e-03,\n",
      "        -3.7628e-02, -2.0950e-02,  3.9328e-02, -1.4541e-02,  2.0381e-02,\n",
      "        -2.5174e-02, -2.8624e-02, -1.5687e-02,  3.2543e-02,  4.3111e-02,\n",
      "        -2.8321e-02, -1.1117e-02,  1.8112e-02, -4.2717e-02,  1.0275e-02,\n",
      "         1.1244e-03,  1.8379e-02,  4.0431e-02,  1.9319e-02, -2.5137e-02,\n",
      "        -6.7368e-03,  1.2679e-02, -1.4839e-02,  3.1860e-02, -1.4001e-02,\n",
      "        -3.6468e-02, -2.0737e-02, -3.2704e-02, -4.8048e-03, -2.8861e-02,\n",
      "         2.8244e-02,  2.1237e-02,  2.0317e-02, -2.1888e-02,  2.6662e-02,\n",
      "         1.3836e-03,  2.2112e-03,  1.9622e-02,  1.6894e-02, -3.7533e-02,\n",
      "        -8.5452e-03,  2.5648e-02, -3.2187e-02,  2.0365e-02,  1.2850e-02,\n",
      "         3.2599e-03, -8.3233e-03, -8.1990e-03,  4.3879e-02,  7.9650e-03,\n",
      "        -2.7058e-02, -1.3107e-02, -1.8649e-02,  2.9612e-02,  1.1405e-02,\n",
      "         9.5219e-03,  9.8502e-03,  3.2929e-03, -4.2253e-02,  2.0000e-02,\n",
      "        -9.6470e-03, -1.6062e-02, -1.9296e-02,  7.7460e-03,  2.0704e-02,\n",
      "         1.5305e-02, -2.6457e-02,  3.8372e-02,  2.8711e-02, -1.6895e-02,\n",
      "         3.1562e-02, -2.9369e-02, -3.1824e-02, -9.7663e-03,  3.2940e-02,\n",
      "         3.4553e-02, -2.7429e-02, -3.3273e-02,  4.1847e-04,  7.3326e-03,\n",
      "         4.4688e-03, -2.3801e-02,  1.9244e-02, -2.0140e-02, -2.5715e-02,\n",
      "         2.1373e-02, -1.7029e-02, -3.0103e-02, -3.5496e-02,  4.3243e-02,\n",
      "         2.1431e-02, -9.4527e-03,  1.7306e-02, -2.4370e-02, -2.6311e-02,\n",
      "        -8.0504e-03,  2.0026e-02,  3.4927e-02, -2.3147e-02, -4.3083e-02,\n",
      "        -4.4062e-02,  7.9306e-03, -2.7716e-03, -3.5715e-02, -1.1579e-02,\n",
      "         3.7133e-03,  1.8212e-02, -3.3741e-02,  4.0142e-02,  2.5905e-02,\n",
      "         3.2433e-02,  3.2725e-03, -1.4575e-02,  4.1097e-02, -1.1275e-02,\n",
      "        -4.0397e-02,  3.6882e-02,  2.8187e-02, -4.6665e-03,  2.5760e-02,\n",
      "         3.2335e-02, -2.2656e-02,  1.8537e-02, -1.0919e-03, -1.4798e-02,\n",
      "         1.3659e-02,  2.3064e-02,  6.6809e-03,  4.0194e-03,  2.3564e-02,\n",
      "        -2.8856e-02, -1.5123e-02,  3.8989e-02,  4.1018e-02,  7.1178e-03,\n",
      "         4.3714e-02,  1.7391e-02, -1.6386e-02, -7.2791e-03,  1.8952e-03,\n",
      "        -2.4907e-02, -8.9143e-03], requires_grad=True)\n",
      "Parameter Size: torch.Size([512])\n",
      "Requires Gradient: True\n",
      "Gradient: None\n",
      "==============================\n",
      "Parameter Name: Parameter containing:\n",
      "tensor([[-0.0427,  0.0391,  0.0155,  ...,  0.0140, -0.0413, -0.0354],\n",
      "        [ 0.0417,  0.0306,  0.0216,  ...,  0.0338, -0.0258, -0.0010],\n",
      "        [-0.0296,  0.0003,  0.0344,  ...,  0.0301,  0.0404, -0.0004],\n",
      "        ...,\n",
      "        [-0.0158,  0.0345, -0.0405,  ...,  0.0250,  0.0056,  0.0241],\n",
      "        [-0.0433, -0.0099, -0.0358,  ...,  0.0176,  0.0166,  0.0172],\n",
      "        [ 0.0206,  0.0299,  0.0030,  ...,  0.0382, -0.0399,  0.0100]],\n",
      "       requires_grad=True)\n",
      "Parameter Size: torch.Size([10, 512])\n",
      "Requires Gradient: True\n",
      "Gradient: None\n",
      "==============================\n",
      "Parameter Name: Parameter containing:\n",
      "tensor([-0.0399, -0.0407,  0.0051, -0.0260, -0.0140, -0.0191,  0.0167,  0.0269,\n",
      "        -0.0141, -0.0380], requires_grad=True)\n",
      "Parameter Size: torch.Size([10])\n",
      "Requires Gradient: True\n",
      "Gradient: None\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(f\"Parameter Name: {param}\")\n",
    "    print(f\"Parameter Size: {param.size()}\")\n",
    "    print(f\"Requires Gradient: {param.requires_grad}\")\n",
    "    if param.grad is not None:\n",
    "        print(f\"Gradient Shape: {param.grad.size()}\")\n",
    "    else:\n",
    "        print(\"Gradient: None\")\n",
    "    print(\"=\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reference\n",
    "https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daconenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
